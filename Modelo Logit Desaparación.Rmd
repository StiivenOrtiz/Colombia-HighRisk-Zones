---
title: "Modelo Logit"
author: "Stiven Ortiz Noreña, Jorge Chantryt, Juan Francisco Ramirez, Esteban Salazar, Andres Cano"
output: word_document
---

# Carga de paquetes

```{r}
paquetes <- c("dplyr", "caret", "haven", "ROSE", "imbalance", "smotefamily", "lattice","here")

# Instalar solo los paquetes que no están instalados
paquetes_faltantes <- paquetes[!(paquetes %in% installed.packages()[, "Package"])]
if (length(paquetes_faltantes) > 0) {
  install.packages(paquetes_faltantes)
}

# Cargar los paquetes
lapply(paquetes, library, character.only = TRUE)


# dplyr es para manejar bases de datos grandes
# caret Machine Learning
# haven ML
# ROSE ML
# imbalance ML (balanceo de datos)
# smotefamily ML
# lattice ML


# Balanceo de datos, cuando hay una categoría que es mayoritaria, puede arruinar todo, entonces se puede hacer balanceo para tener resultados mas concistentes 
```

# Modelo de clasificación

```{r}
DESAPARICIONES_FORZADAS_7 <- read.csv(here("data", "DESAPARICIONES_CLEAN.csv"), sep = ",")

# Verificar el balanceo de la variable Y
table(DESAPARICIONES_FORZADAS_7$Riesgo)

# Para este caso dado, 0 = 98728 y 1 = 95758, dado  que la diferencia es pequeña, no se recomienda balancear la base de datos, pero si se desea balancear, se puede hacer de la siguiente manera:

# require(dplyr)
# Basef1 <- Basef %>%
#           group_by(y) %>%
#           sample(min(table(Basef$y))) %>%
#           ungroup()
#           table(Basef1$y)

DESAPARICIONES_FORZADAS_8 <- DESAPARICIONES_FORZADAS_7 %>%
  group_by(Riesgo) %>%
  slice_sample(n = min(table(DESAPARICIONES_FORZADAS_7$Riesgo))) %>%
  ungroup()

table(DESAPARICIONES_FORZADAS_8$Riesgo)

# Si por ejemplo en la variable Y, la categoría 1 tiene 20000 valores y la categoría 2 tiene 2000 valores. la función sample, selecciona una muestra aleatoria de tamaño 2000 de la categoría 1, con eso la nueva base tendrá 2000 valores en cada categoría.
```

```{r}
table(DESAPARICIONES_FORZADAS_8$Riesgo)

DESAPARICIONES_FORZADAS_8 <- DESAPARICIONES_FORZADAS_8 %>%
  group_by(Nombre_Municipio) %>%
  filter(n() > 2) %>%
  ungroup() # Para eliminar los municipios con menos de 2 observaciones

DESAPARICIONES_FORZADAS_8 <- droplevels(DESAPARICIONES_FORZADAS_8) # Para eliminar los niveles vacíos de la variable Nombre_Municipio

#table(DESAPARICIONES_FORZADAS_8$Nombre_Municipio)
table(DESAPARICIONES_FORZADAS_8$Riesgo)


# Como 0 = 40958 y 1 = 5845, entonces tenemos que balancear la base de datos, dado que la diferencia es muy grande.
```


## Generación de bases de entrenamiento y prueba

```{r}
require(caret)

DESAPARICIONES_FORZADAS_8$Anio_hecho <- as.numeric(as.character(DESAPARICIONES_FORZADAS_8$Anio_hecho))

BaseEntrenamiento <- createDataPartition(y = DESAPARICIONES_FORZADAS_8$Nombre_Municipio, p = 0.7, list = FALSE)
Entrenamiento <- DESAPARICIONES_FORZADAS_8[BaseEntrenamiento, ] # Base de entrenamiento
Test <- DESAPARICIONES_FORZADAS_8[-BaseEntrenamiento, ] # Base de prueba

# Explicación de DATOS[-VARIABLE]: Este código significa que se está seleccionando todas las filas de la base de datos, pero excluyendo las filas que están en la variable BaseEntrenamiento. En otras palabras, se está creando una nueva base de datos (Test) que contiene solo las filas que no están en la base de entrenamiento (BaseEntrenamiento). 

dim(Entrenamiento) # Dimensiones de la base de entrenamiento
dim(Test) # Dimensiones de la base de prueba
```

A partir del entrenamiento se genera el modelo LOGIT para clasificar los individuos en la vairbale $y$ (cotización a pensiones) y se evalua el modelo con la base de prueba.

```{r}
modelo.logit <- glm(Riesgo ~ ., data = Entrenamiento, family="binomial")
#modelo.logit <- glm(y ~ ., data = Entrenamiento, family = binomial(link = "logit")) # Modelo logit

summary(modelo.logit) # Resumen del modelo```
```

```{r}
Entrenamientof <- predict(modelo.logit, newdata = Test, type = "response") # Predecir la probabilidad de que el individuo cotice a pensiones
head(Entrenamientof) # Ver las primeras filas de la predicción
```

```{r}
library(caret)

y_pred <- factor(ifelse(Entrenamientof > 0.5, 1, 0))
y_real <- as.factor(Test$Riesgo)
levels(y_pred) <- c("Si", "No")
levels(y_real) <- c("Si", "No")
table(Prediccion = y_pred, Realidad = y_real) # Tabla de confusión
```

```{r}
conf_matrix <- confusionMatrix(y_pred, y_real)
conf_matrix
```